<!DOCTYPE html>
<html>
<head>
<title>Page Title</title>
<style>
      body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            margin: 20px;
            background-color: #fff;
        }
        h1 {
            text-align: center;
            color: #333;
        }
        ol {
            padding-left: 10px;
        }
        li {
            margin-bottom: 15px;
            padding: 10px;
            background: #ffffff;
            border-radius: 8px;
            box-shadow: 0 2px 5px rgba(0, 0, 0, 0.4);
        }
        strong {
            color: #0056b3;
        }
    </style>
</head>
<body>
<ol>
    <li><strong>What is Machine Learning?</strong> - A field of AI focused on enabling machines to learn from data.</li>
    <li><strong>AI Vs ML Vs DL for Beginners in Hindi</strong> - Differences between Artificial Intelligence, Machine Learning, and Deep Learning.</li>
    <li><strong>Types of Machine Learning for Beginners</strong> - Overview of supervised, unsupervised, and reinforcement learning.</li>
    <li><strong>Batch Machine Learning</strong> - Learning from a complete dataset at once.</li>
    <li><strong>Online Machine Learning</strong> - Learning incrementally from data streams.</li>
    <li><strong>Instance-Based Vs Model-Based Learning</strong> - Comparison of learning from examples vs. learning a model.</li>
    <li><strong>Challenges in Machine Learning</strong> - Common obstacles like overfitting, underfitting, and data quality issues.</li>
    <li><strong>Application of Machine Learning</strong> - Use cases in healthcare, finance, marketing, etc.</li>
    <li><strong>Machine Learning Development Life Cycle</strong> - Stages from data collection to model deployment.</li>
    <li><strong>Data Engineer Vs Data Analyst Vs Data Scientist Vs ML Engineer</strong> - Roles and responsibilities in data and ML fields.</li>
    <li><strong>What are Tensors</strong> - Multi-dimensional arrays used in ML and Deep Learning.</li>
    <li><strong>Installing Anaconda For Data Science</strong> - Setting up Anaconda for a data science environment.</li>
    <li><strong>End to End Toy Project</strong> - A simple ML project from data collection to model deployment.</li>
    <li><strong>How to Frame a Machine Learning Problem</strong> - Defining objectives and metrics for ML tasks.</li>
    <li><strong>Working with CSV files</strong> - Handling data in Comma-Separated Values format.</li>
    <li><strong>Working with JSON/SQL</strong> - Managing data in JSON format and SQL databases.</li>
    <li><strong>Fetching Data From an API</strong> - How to retrieve data from application programming interfaces.</li>
    <li><strong>Fetching data using Web Scraping</strong> - Extracting data from websites programmatically.</li>
    <li><strong>Understanding Your Data</strong> - Importance of data exploration and insights.</li>
    <li><strong>EDA using Univariate Analysis</strong> - Analyzing single variables for insights.</li>
    <li><strong>EDA using Bivariate and Multivariate Analysis</strong> - Exploring relationships between multiple variables.</li>
    <li><strong>Pandas Profiling</strong> - Generating reports for quick data analysis using Pandas.</li>
    <li><strong>What is Feature Engineering</strong> - Process of selecting and transforming features for better model performance.</li>
    <li><strong>Feature Scaling - Standardization</strong> - Normalizing data to have a mean of 0 and standard deviation of 1.</li>
    <li><strong>Feature Scaling - Normalization</strong> - Rescaling features to a range, typically [0, 1].</li>
    <li><strong>Encoding Categorical Data</strong> - Converting categorical variables into numerical format.</li>
    <li><strong>One Hot Encoding</strong> - A method of converting categorical data into binary format.</li>
    <li><strong>Column Transformer in Machine Learning</strong> - Applying different transformations to different columns of data.</li>
    <li><strong>Machine Learning Pipelines A-Z</strong> - Structuring end-to-end ML workflows efficiently.</li>
    <li><strong>Function Transformer</strong> - Custom transformations in ML pipelines.</li>
    <li><strong>Power Transformer</strong> - A technique to stabilize variance and make the data more Gaussian-like.</li>
    <li><strong>Binning and Binarization</strong> - Grouping continuous data into discrete bins and converting variables into binary.</li>
    <li><strong>Handling Mixed Variables</strong> - Techniques for dealing with different data types in datasets.</li>
    <li><strong>Handling Date and Time Variables</strong> - Managing and extracting features from date/time data.</li>
    <li><strong>Handling Missing Data - Part 1</strong> - Strategies for dealing with incomplete data.</li>
    <li><strong>Handling Missing Data - Numerical Data</strong> - Techniques for imputing missing values in numerical columns.</li>
    <li><strong>Handling Missing Categorical Data</strong> - Strategies for filling gaps in categorical data.</li>
    <li><strong>Missing Indicator</strong> - A method to flag missing data as a feature.</li>
    <li><strong>KNN Imputer</strong> - A method for imputing missing values using k-nearest neighbors.</li>
    <li><strong>Multivariate Imputation by Chained Equations</strong> - A more sophisticated technique for imputing missing values.</li>
    <li><strong>What are Outliers</strong> - Data points that significantly differ from the rest of the dataset.</li>
    <li><strong>Outlier Detection and Removal using Z-score Method</strong> - Identifying outliers using standard deviations.</li>
    <li><strong>Outlier Detection and Removal using the IQR Method</strong> - Using interquartile range to identify outliers.</li>
    <li><strong>Outlier Detection using the Percentile Method</strong> - Finding outliers based on data percentiles.</li>
    <li><strong>Feature Construction</strong> - Creating new features from existing data to improve model performance.</li>
    <li><strong>Curse of Dimensionality</strong> - Challenges arising from high-dimensional data spaces.</li>
    <li><strong>Principal Component Analysis (PCA) - Part 1</strong> - Technique for reducing dimensionality by transforming features.</li>
    <li><strong>Principal Component Analysis (PCA) - Part 2</strong> - Continued exploration of PCA's applications.</li>
    <li><strong>Principal Component Analysis (PCA) - Part 3</strong> - Further insights into PCA and its interpretation.</li>
    <li><strong>Simple Linear Regression</strong> - A method for modeling the relationship between two variables.</li>
    <li><strong>Simple Linear Regression - Mathematical Formulation</strong> - The equations behind simple linear regression.</li>
    <li><strong>Regression Metrics</strong> - Metrics used to evaluate regression models' performance.</li>
    <li><strong>Multiple Linear Regression - Geometric Intuition</strong> - Understanding multiple regression through geometry.</li>
    <li><strong>Multiple Linear Regression - Part 2</strong> - Further insights and implications of multiple regression.</li>
    <li><strong>Multiple Linear Regression - Part 3</strong> - Advanced concepts in multiple linear regression.</li>
    <li><strong>Gradient Descent From Scratch</strong> - Implementing the gradient descent optimization algorithm.</li>
    <li><strong>Batch Gradient Descent</strong> - A variant of gradient descent using the entire dataset.</li>
    <li><strong>Stochastic Gradient Descent</strong> - Using single data points for gradient updates.</li>
    <li><strong>Mini-Batch Gradient Descent</strong> - A compromise between batch and stochastic methods.</li>
    <li><strong>Polynomial Regression</strong> - Extending linear regression to polynomial relationships.</li>
    <li><strong>Bias Variance Trade-off</strong> - Balancing model complexity and error types.</li>
    <li><strong>Ridge Regression - Part 1</strong> - Regularization technique to prevent overfitting.</li>
    <li><strong>Ridge Regression - Part 2</strong> - Understanding the mechanics behind ridge regression.</li>
    <li><strong>Ridge Regression - Part 3</strong> - Further analysis and applications of ridge regression.</li>
    <li><strong>5 Key Points - Ridge Regression</strong> - Important aspects to remember about ridge regression.</li>
    <li><strong>Lasso Regression</strong> - A regularization method that can reduce coefficients to zero.</li>
    <li><strong>Why Lasso Regression creates sparsity?</strong> - Explaining the sparsity effect in lasso regression.</li>
    <li><strong>ElasticNet Regression</strong> - A combination of ridge and lasso regression techniques.</li>
    <li><strong>Logistic Regression - Part 1</strong> - Introduction to logistic regression for binary outcomes.</li>
    <li><strong>Logistic Regression - Part 2</strong> - Mathematical details and applications of logistic regression.</li>
    <li><strong>Logistic Regression - Part 3</strong> - Advanced topics in logistic regression.</li>
    <li><strong>Logistic Regression - Part 4</strong> - Further exploration of logistic regression concepts.</li>
    <li><strong>Derivative of Sigmoid Function</strong> - Understanding the sigmoid function's role in logistic regression.</li>
    <li><strong>Logistic Regression - Part 5</strong> - Evaluation and interpretation of logistic regression models.</li>
    <li><strong>Accuracy and Confusion Matrix</strong> - Tools for assessing classification model performance.</li>
    <li><strong>Precision, Recall and F1 Score</strong> - Metrics for evaluating binary classifiers.</li>
    <li><strong>Softmax Regression</strong> - Generalization of logistic regression for multi-class problems.</li>
    <li><strong>Polynomial Features in Logistic Regression</strong> - Adding polynomial terms to enhance model capability.</li>
    <li><strong>Logistic Regression Hyperparameters</strong> - Tuning options to optimize logistic regression models.</li>
    <li><strong>Decision Trees Geometric Intuition</strong> - Understanding decision tree structures visually.</li>
    <li><strong>Decision Trees - Hyperparameters</strong> - Key settings that influence decision tree performance.</li>
    <li><strong>Regression Trees</strong> - Decision trees specifically for regression tasks.</li>
    <li><strong>Awesome Decision Tree Visualization</strong> - Techniques for visualizing decision trees effectively.</li>
    <li><strong>Introduction to Ensemble Learning</strong> - Combining multiple models to improve performance.</li>
    <li><strong>Voting Ensemble - Part 1</strong> - Basics of ensemble methods that use majority voting.</li>
    <li><strong>Voting Ensemble - Part 2</strong> - Further details on implementing voting ensembles.</li>
    <li><strong>Voting Ensemble - Part 3</strong> - Advanced concepts and variations of voting ensembles.</li>
    <li><strong>Bagging - Introduction</strong> - Ensemble method that reduces variance through bootstrap sampling.</li>
    <li><strong>Bagging Ensemble - Part 2</strong> - Implementing bagging for improved model performance.</li>
    <li><strong>Bagging Ensemble - Part 3</strong> - Advanced techniques in bagging ensembles.</li>
    <li><strong>Introduction to Random Forest</strong> - An ensemble method using multiple decision trees.</li>
    <li><strong>How Random Forest Performs So Well?</strong> - Understanding the advantages of random forests.</li>
    <li><strong>Bagging Vs Random Forest</strong> - Comparing these two ensemble techniques.</li>
    <li><strong>Random Forest Hyper-parameters</strong> - Key settings to optimize random forest models.</li>
    <li><strong>Hyperparameter Tuning Random Forest</strong> - Techniques to fine-tune random forest parameters.</li>
    <li><strong>OOB Score in Random Forest</strong> - Out-of-bag scoring as a validation method for random forests.</li>
    <li><strong>Feature Importance using Random Forest and Decision Trees</strong> - Assessing the significance of features in models.</li>
    <li><strong>How Adaboost Classifier Works?</strong> - An overview of the AdaBoost ensemble method.</li>
    <li><strong>AdaBoost - A Step by Step Explanation</strong> - Detailed explanation of how AdaBoost functions.</li>
    <li><strong>AdaBoost Algorithm</strong> - The mechanics behind the AdaBoost algorithm.</li>
    <li><strong>AdaBoost Hyperparameters</strong> - Key parameters for tuning AdaBoost models.</li>
    <li><strong>Bagging Vs Boosting</strong> - Comparing two popular ensemble methods.</li>
    <li><strong>K-Means Clustering Algorithm</strong> - A method for partitioning data into clusters.</li>
    <li><strong>K-Means Clustering Algorithm in Python</strong> - Implementing K-Means using Python libraries.</li>
    <li><strong>K-Means Clustering Algorithm From Scratch</strong> - Building K-Means from the ground up.</li>
    <li><strong>Gradient Boosting Explained</strong> - An introduction to the gradient boosting framework.</li>
    <li><strong>Gradient Boosting Regression - Part 2</strong> - Continuing the discussion on gradient boosting for regression.</li>
    <li><strong>Gradient Boosting for Classification</strong> - Applying gradient boosting techniques to classification tasks.</li>
    <li><strong>Stacking and Blending Ensembles</strong> - Advanced ensemble techniques that combine models differently.</li>
    <li><strong>Agglomerative Hierarchical Clustering</strong> - A method of clustering that builds a hierarchy of clusters.</li>
    <li><strong>What is K Nearest Neighbors?</strong> - A simple, instance-based learning algorithm for classification and regression.</li>
    <li><strong>What are the main Assumptions of Linear Regression?</strong> - Key assumptions underlying linear regression analysis.</li>
    <li><strong>Support Vector Machines - Geometric Intuition</strong> - Understanding SVMs through geometric principles.</li>
    <li><strong>Mathematics of SVM - Hard margin SVM</strong> - Exploring the mathematical foundation of SVMs.</li>
    <li><strong>Mathematics of Support Vector Machine - Soft Margin SVM</strong> - Understanding soft margins in SVMs.</li>
    <li><strong>Kernel Trick in SVM - Code Example</strong> - Using kernels to enable SVMs to classify non-linear data.</li>
    <li><strong>Kernel Trick in SVM - Geometric Intuition</strong> - Visualizing how kernels work in SVMs.</li>
    <li><strong>Naive Bayes Classifier - Part 1</strong> - Introduction to Naive Bayes for classification tasks.</li>
    <li><strong>Naive Bayes Classifier - Part 2</strong> - Deep dive into Naive Bayes methodology.</li>
    <li><strong>Naive Bayes Classifier - Part 3</strong> - Further exploration of Naive Bayes classifiers.</li>
    <li><strong>Naive Bayes Classifier - Part 4</strong> - Applications and variations of Naive Bayes.</li>
    <li><strong>Naive Bayes Classifier - Part 5</strong> - More insights into Naive Bayes algorithms.</li>
    <li><strong>Naive Bayes Classifier - Part 6</strong> - Advanced techniques and considerations in Naive Bayes.</li>
    <li><strong>Naive Bayes Classifier - Part 7</strong> - Comprehensive analysis of the Naive Bayes approach.</li>
    <li><strong>Naive Bayes Part 9 - Handling Numerical Data</strong> - Strategies for processing numerical data in Naive Bayes.</li>
    <li><strong>Introduction to XGBOOST</strong> - An overview of the XGBoost framework for boosting.</li>
    <li><strong>XGBoost for Regression</strong> - Applying XGBoost to regression problems.</li>
    <li><strong>XGBoost For Classification</strong> - Using XGBoost for classification tasks.</li>
    <li><strong>The Maths Behind XGBoost</strong> - Mathematical concepts that drive XGBoost's effectiveness.</li>
    <li><strong>DBSCAN Clustering Algorithms</strong> - Density-based clustering method for identifying clusters.</li>
    <li><strong>Imbalanced Data in Machine Learning</strong> - Challenges and solutions for datasets with uneven class distribution.</li>
</ol>


</body>
</html>
